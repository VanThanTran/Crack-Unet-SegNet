{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary gdown\n#!pip install albumentations==0.4.6","metadata":{"execution":{"iopub.status.busy":"2022-01-27T10:57:38.905448Z","iopub.execute_input":"2022-01-27T10:57:38.905834Z","iopub.status.idle":"2022-01-27T10:57:58.708358Z","shell.execute_reply.started":"2022-01-27T10:57:38.905739Z","shell.execute_reply":"2022-01-27T10:57:58.707402Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#import warnings\n#warnings.simplefilter('error', UserWarning)\n\n#from IPython.core.interactiveshell import InteractiveShell\n#InteractiveShell.ast_node_interactivity = \"all\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torchvision.transforms as tfs\nimport torchvision.models\nfrom torchsummary import summary\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\nfrom IPython.display import clear_output\nfrom tqdm.notebook import tqdm\nimport pickle\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2022-01-27T10:58:40.925441Z","iopub.execute_input":"2022-01-27T10:58:40.925698Z","iopub.status.idle":"2022-01-27T10:58:40.931914Z","shell.execute_reply.started":"2022-01-27T10:58:40.925669Z","shell.execute_reply":"2022-01-27T10:58:40.931112Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncontent_dir = '/kaggle/working/PH2Dataset'\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2022-01-27T10:58:47.549713Z","iopub.execute_input":"2022-01-27T10:58:47.550242Z","iopub.status.idle":"2022-01-27T10:58:47.555016Z","shell.execute_reply.started":"2022-01-27T10:58:47.550199Z","shell.execute_reply":"2022-01-27T10:58:47.554336Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data","metadata":{}},{"cell_type":"code","source":"if not os.path.exists(content_dir):\n    print('Download dataset...')\n    # !wget --quiet https://www.dropbox.com/s/k88qukc20ljnbuo/PH2Dataset.rar\n    !gdown https://drive.google.com/uc?id=1JHRw-LcPoHoApGNoub2b-DgrSWnRw-ZB -O PH2Dataset.zip\n    # print('Install unrar...', end='')\n    # !apt-get -qq install unrar > /dev/null 2>&1\n    # print('done.')\n    print('Extract archive files...', end='')\n    #!unrar x -idq PH2Dataset.rar\n    !unzip -q PH2Dataset.zip\n    print('done.')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T10:58:56.472855Z","iopub.execute_input":"2022-01-27T10:58:56.473678Z","iopub.status.idle":"2022-01-27T10:59:01.141848Z","shell.execute_reply.started":"2022-01-27T10:58:56.473642Z","shell.execute_reply":"2022-01-27T10:59:01.140964Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class CustomDataSet(Dataset):\n    def __init__(self, main_dir, transform):\n        self.transform = transform\n        self.samples = []\n        self.labels = []\n        for root, dirs, files in os.walk(main_dir):\n            if root.endswith('_Dermoscopic_Image'):\n                self.samples.append(os.path.join(root, files[0]))\n            if root.endswith('_lesion'):\n                self.labels.append(os.path.join(root, files[0]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        # image = Image.open(self.samples[idx])\n        # label = Image.open(self.labels[idx])\n        image = cv2.imread(self.samples[idx])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = cv2.imread(self.labels[idx], cv2.IMREAD_GRAYSCALE)\n        transformed = self.transform(image=image, mask=label)\n        tensor_image = transformed['image'].transpose(2, 0, 1)\n        label_image = transformed['mask'][np.newaxis, :]\n        tensor_image = torch.FloatTensor(tensor_image) / 255\n        label_image = torch.FloatTensor(label_image) / 255\n        #print(tensor_image.shape, label_image.shape)\n        #print(tensor_image.min(), tensor_image.max(), label_image.min(), label_image.max())\n        return tensor_image, label_image\n    \n#     def __getitem__(self, idx):\n#         image = Image.open(self.samples[idx])\n#         tensor_image = self.transform(image)\n#         label = Image.open(self.labels[idx])\n#         label_image = self.transform(label)\n#         print(tensor_image.min(), tensor_image.max(), label_image.min(), label_image.max())\n#         return tensor_image, label_image","metadata":{"execution":{"iopub.status.busy":"2022-01-27T10:59:21.889871Z","iopub.execute_input":"2022-01-27T10:59:21.890366Z","iopub.status.idle":"2022-01-27T10:59:21.911684Z","shell.execute_reply.started":"2022-01-27T10:59:21.890324Z","shell.execute_reply":"2022-01-27T10:59:21.910738Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([\n    A.Resize(256, 256),\n#     A.HorizontalFlip(),\n#     A.VerticalFlip(),\n#     A.augmentations.geometric.Affine(\n#         scale={'x':(1.0, 1.2), 'y':(1.0, 1.2)},\n# #        cval=[55, 51, 49],\n# #        mode=cv2.BORDER_CONSTANT\n#     )\n    #A.ToFloat(),\n    #A.pytorch.ToTensorV2(),\n    #A.Normalize(mean=0, std=1),\n    #tfs.RandomAffine(10,translate=(0.1, 0.1), scale=(0.9, 1.1)),\n])\n\n# transform = tfs.Compose([\n#     tfs.Resize((256, 256)),\n#     tfs.ToTensor(),\n# ])\n\ndermoscopic_dataset = CustomDataSet(os.path.join(content_dir, 'PH2 Dataset images'), transform=transform)\n\nidx = np.random.choice(len(dermoscopic_dataset), len(dermoscopic_dataset), False)\ntrain_idx, valid_idx, test_idx = np.split(idx, [70, 90])\n#train_idx, test_idx = np.split(idx, [80])\n\ndataset_train = Subset(dermoscopic_dataset, train_idx)\ndataset_valid = Subset(dermoscopic_dataset, valid_idx)\ndataset_test  = Subset(dermoscopic_dataset, test_idx)\n\ndataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\ndataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\ndataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:01:21.442445Z","iopub.execute_input":"2022-01-27T11:01:21.443217Z","iopub.status.idle":"2022-01-27T11:01:21.462583Z","shell.execute_reply.started":"2022-01-27T11:01:21.443175Z","shell.execute_reply":"2022-01-27T11:01:21.461837Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"def show_dermoscopic_imgs(images, labels, threshold=None):\n    images = images.numpy().transpose(0, 2, 3, 1)\n    labels = labels.numpy().transpose(0, 2, 3, 1)\n    if threshold is not None:\n        labels = np.where(labels > threshold, 1, 0)\n    plt.figure(figsize=(18, 6))\n    for i in range(4):\n        plt.subplot(2, 6, i+1)\n        plt.imshow(images[i])\n        plt.axis(\"off\")\n\n        plt.subplot(2, 6, i+7)\n        plt.imshow(labels[i], cmap='gray')\n        plt.axis(\"off\")\n    #plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:04:03.162493Z","iopub.execute_input":"2022-01-27T11:04:03.162763Z","iopub.status.idle":"2022-01-27T11:04:03.170062Z","shell.execute_reply.started":"2022-01-27T11:04:03.162733Z","shell.execute_reply":"2022-01-27T11:04:03.169000Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"images, labels = next(iter(dataloader_train))\nshow_dermoscopic_imgs(images, labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:04:05.467196Z","iopub.execute_input":"2022-01-27T11:04:05.467737Z","iopub.status.idle":"2022-01-27T11:04:06.198385Z","shell.execute_reply.started":"2022-01-27T11:04:05.467699Z","shell.execute_reply":"2022-01-27T11:04:06.197712Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def show_loss(history):\n    plt.figure(figsize=(12, 8))\n    plt.plot(history)\n    plt.title('Loss')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:04:21.051260Z","iopub.execute_input":"2022-01-27T11:04:21.051596Z","iopub.status.idle":"2022-01-27T11:04:21.061101Z","shell.execute_reply.started":"2022-01-27T11:04:21.051560Z","shell.execute_reply":"2022-01-27T11:04:21.060137Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Metrics\n\nGood summary: [A survey of loss functions for semantic segmentation](https://arxiv.org/pdf/2006.14822.pdf)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T13:13:39.409414Z","iopub.execute_input":"2021-11-18T13:13:39.409711Z","iopub.status.idle":"2021-11-18T13:13:39.413556Z","shell.execute_reply.started":"2021-11-18T13:13:39.409677Z","shell.execute_reply":"2021-11-18T13:13:39.412683Z"}}},{"cell_type":"markdown","source":"## IoU scoring metric\n\n$$I o U=\\frac{\\text {target } \\cap \\text { prediction }}{\\text {target } \\cup{prediction }}$$","metadata":{}},{"cell_type":"code","source":"SMOOTH = 1e-6\n# https://www.kaggle.com/iezepov/fast-iou-scoring-metric-in-pytorch-and-numpy\ndef iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n    outputs = outputs.byte()\n    labels = labels.byte()\n    #print(outputs)\n    # You can comment out this line if you are passing tensors of equal shape\n    # But if you are passing output from UNet or something it will most probably\n    # be with the BATCH x 1 x H x W shape\n    #outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n    # thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n    # return thresholded  # Or thresholded.mean() if you are interested in average across the batch\n    return iou","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:05:59.122987Z","iopub.execute_input":"2022-01-27T11:05:59.123620Z","iopub.status.idle":"2022-01-27T11:05:59.129227Z","shell.execute_reply.started":"2022-01-27T11:05:59.123579Z","shell.execute_reply":"2022-01-27T11:05:59.128450Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## BCE Loss\n\n$$\\mathcal L_{BCE}(y, \\hat y) = -\\sum_i \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right]$$","metadata":{"execution":{"iopub.status.busy":"2021-11-18T13:27:55.204072Z","iopub.execute_input":"2021-11-18T13:27:55.204598Z","iopub.status.idle":"2021-11-18T13:27:55.207505Z","shell.execute_reply.started":"2021-11-18T13:27:55.204565Z","shell.execute_reply":"2021-11-18T13:27:55.206925Z"}}},{"cell_type":"code","source":"class BCELoss_classic(nn.Module):\n    def __init__(self, reduction='mean'):\n        super().__init__()\n        if reduction not in ('mean', 'sum'):\n            raise ValueError('\"{}\" is not a valid mode for reduction. Only \"mean\"'\n                             'and \"sum\" are allowed.'.format(rediction))\n        self.reduction = reduction\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        # outputs = torch.clamp(outputs, 0, 1)\n        outputs = torch.sigmoid(outputs)\n        bce = labels * torch.log(outputs + SMOOTH) + (1 - labels) * torch.log(1 - outputs + SMOOTH)\n        if self.reduction == 'mean':\n            return -torch.mean(bce)\n        elif self.reduction == 'sum':\n            return -torch.sum(bce)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:06:11.201870Z","iopub.execute_input":"2022-01-27T11:06:11.202162Z","iopub.status.idle":"2022-01-27T11:06:11.209628Z","shell.execute_reply.started":"2022-01-27T11:06:11.202131Z","shell.execute_reply":"2022-01-27T11:06:11.208927Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"$$\\mathcal L_{BCE}(y, \\hat y) = \\hat y - y\\hat y + \\log\\left(1+\\exp(-\\hat y)\\right)$$","metadata":{}},{"cell_type":"code","source":"class BCELoss_with_logits(nn.Module):\n    def __init__(self, reduction='mean', truncate=False):\n        super().__init__()\n        if reduction not in ('mean', 'sum'):\n            raise ValueError('\"{}\" is not a valid mode for reduction. Only \"mean\"'\n                             'and \"sum\" are allowed.'.format(rediction))\n        self.reduction = reduction\n        self.truncate = truncate\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        # classical without sigmoid\n        # but you need to cut off large negative logits, otherwise it will be -inf -> nan \n        if self.truncate:\n            outputs = torch.sigmoid(outputs)\n        outputs = outputs.float()\n        labels = labels.float()\n        # print(torch.min(outputs))\n        bce = outputs - labels * outputs + torch.log(1 + torch.exp(-outputs))\n        if self.reduction == 'mean':\n            return torch.mean(bce)\n        elif self.reduction == 'sum':\n            return torch.sum(bce)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:06:50.380966Z","iopub.execute_input":"2022-01-27T11:06:50.381657Z","iopub.status.idle":"2022-01-27T11:06:50.388605Z","shell.execute_reply.started":"2022-01-27T11:06:50.381621Z","shell.execute_reply":"2022-01-27T11:06:50.387942Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#torch.mean(torch.log(1 + torch.exp(torch.tensor(255))))","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:07:24.490865Z","iopub.execute_input":"2022-01-27T11:07:24.491318Z","iopub.status.idle":"2022-01-27T11:07:24.561982Z","shell.execute_reply.started":"2022-01-27T11:07:24.491267Z","shell.execute_reply":"2022-01-27T11:07:24.561200Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"output = torch.Tensor([\n    [-0.4717,  0.8484,  0.7424],\n    [ 0.0880,  0.1379,  0.8387],\n    [ 0.3874, -1.8205,  1.5422]\n])\ntarget = torch.Tensor([\n    [0, 1, 0],\n    [1, 0, 1],\n    [0, 1, 0]\n])\nsigm = nn.Sigmoid()\n\nprint(\n    output,\n    target,\n    nn.BCELoss(reduction='mean')(sigm(output), target),\n    BCELoss_classic(reduction='mean')(output, target),\n    BCELoss_with_logits(reduction='mean')(output, target),\n    sep='\\n'\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:07:41.284500Z","iopub.execute_input":"2022-01-27T11:07:41.285320Z","iopub.status.idle":"2022-01-27T11:07:41.315284Z","shell.execute_reply.started":"2022-01-27T11:07:41.285265Z","shell.execute_reply":"2022-01-27T11:07:41.314512Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Dice Loss\n\n$$D(X,Y)=\\frac{2|X\\cap Y|}{|X|+|Y|}$$\n\n$$\\mathcal L_D(X,Y) = 1-\\frac{1}{256 \\times 256} \\times \\sum_i\\frac{2X_iY_i}{X_i+Y_i}.$$","metadata":{}},{"cell_type":"code","source":"class DiceLoss(nn.Module):\n    def __init__(self, reduction='mean'):\n        super().__init__()\n\n#     # not work, why?\n#     def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n#         coef = 1 / (outputs.shape[0] * outputs.shape[2] * outputs.shape[3])\n#         outputs = torch.sigmoid(outputs)\n#         num = 2 * outputs * labels\n#         den = outputs + labels\n#         res = 1 - coef * ((num + 1)/(den + 1)).sum()\n#         return res\n\n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        outputs = torch.sigmoid(outputs)\n        num = 2 * (outputs * labels).sum()\n        den = (outputs + labels).sum()\n        res = 1 - (num + SMOOTH) / (den + SMOOTH)\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:08:19.197662Z","iopub.execute_input":"2022-01-27T11:08:19.198308Z","iopub.status.idle":"2022-01-27T11:08:19.204335Z","shell.execute_reply.started":"2022-01-27T11:08:19.198266Z","shell.execute_reply":"2022-01-27T11:08:19.203477Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Focal Loss\n\n$$FL(p_t) = -\\alpha_t(1-p_t)^\\gamma log(p_t)$$\n$$CE(p,y) = CE(p_t) = -log(p_t)$$\n$$p_t = e^{-CE(p_t)}$$\n$$FL(p_t) = \\alpha_t(1-e^{-CE(p_t)})^\\gamma CE(p_t)$$","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:15:44.629785Z","iopub.execute_input":"2021-11-21T09:15:44.630127Z","iopub.status.idle":"2021-11-21T09:15:44.635131Z","shell.execute_reply.started":"2021-11-21T09:15:44.630085Z","shell.execute_reply":"2021-11-21T09:15:44.634061Z"}}},{"cell_type":"code","source":"# https://arxiv.org/pdf/1708.02002.pdf\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha: int = 1, gamma: int = 2):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        bce_logit = nn.BCEWithLogitsLoss()\n        ce = bce_logit(outputs, labels)\n        pt = torch.exp(-ce)\n        fl = self.alpha * torch.pow((1 - pt), self.gamma) * ce\n        return fl","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:08:24.786633Z","iopub.execute_input":"2022-01-27T11:08:24.786914Z","iopub.status.idle":"2022-01-27T11:08:24.794579Z","shell.execute_reply.started":"2022-01-27T11:08:24.786862Z","shell.execute_reply":"2022-01-27T11:08:24.793697Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Tversky Loss\n\n[Tversky loss function for image segmentation using 3D fully convolutional deep networks](https://arxiv.org/abs/1706.05721)\n\n$$TI(p,\\hat p) = \\frac{p\\hat p}{p\\hat p + \\beta(1 − p)\\hat p + (1 − \\beta)p(1 − \\hat p)}$$\n$$TL(p,\\hat p) = 1 - \\frac{1 + p\\hat p}{1+ p\\hat p + \\beta(1 − p)\\hat p + (1 − \\beta)p(1 − \\hat p)}$$","metadata":{}},{"cell_type":"code","source":"class TverskyLoss(nn.Module):\n    def __init__(self, alpha:int = 0.5, beta:int = 0.5):\n        super().__init__()\n        self.alpha = alpha\n        self.beta = beta\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        outputs = torch.sigmoid(outputs)\n        pp = (labels * outputs).sum()\n        den1 = self.alpha * ((1 - labels) * outputs).sum()\n        den2 = self.beta * (labels * (1 - outputs)).sum()\n        tl = 1 - (1 + pp) / (1 + pp + den1 + den2)\n        return tl       ","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:08:37.315571Z","iopub.execute_input":"2022-01-27T11:08:37.315890Z","iopub.status.idle":"2022-01-27T11:08:37.324721Z","shell.execute_reply.started":"2022-01-27T11:08:37.315841Z","shell.execute_reply":"2022-01-27T11:08:37.321951Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Focal Tversky Loss","metadata":{}},{"cell_type":"code","source":"class FocalTverskyLoss(nn.Module):\n    def __init__(self, alpha:int = 0.5, beta:int = 0.5, gamma:int = 2):\n        super().__init__()\n        self.gamma = gamma\n        self.tl = TverskyLoss(alpha, beta)\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        tl = self.tl(outputs, labels)\n        return torch.pow(tl, self.gamma)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:08:45.949171Z","iopub.execute_input":"2022-01-27T11:08:45.950020Z","iopub.status.idle":"2022-01-27T11:08:45.956197Z","shell.execute_reply.started":"2022-01-27T11:08:45.949967Z","shell.execute_reply":"2022-01-27T11:08:45.955426Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Lovasz Loss","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/67791\nclass LovaszLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        #outputs = torch.sigmoid(outputs)\n        outputs = outputs.flatten()\n        labels = labels.flatten()\n        signs = 2 * labels.float() - 1\n        errors = (1 - outputs * signs)\n        errors_sorted, indices = torch.sort(errors, dim=0, descending=True)\n        gt_sorted = labels[indices.data]\n\n        # gradient\n        gts = gt_sorted.sum()\n        intersection = gts - gt_sorted.float().cumsum(0)\n        union = gts + (1 - gt_sorted).float().cumsum(0)\n        grad = 1. - intersection / union\n\n        p = len(gt_sorted)\n        grad[1:p] = grad[1:p] - grad[0:-1]\n       \n        loss = torch.dot(torch.relu(errors_sorted), grad)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:08:56.748306Z","iopub.execute_input":"2022-01-27T11:08:56.748586Z","iopub.status.idle":"2022-01-27T11:08:56.757925Z","shell.execute_reply.started":"2022-01-27T11:08:56.748554Z","shell.execute_reply":"2022-01-27T11:08:56.757151Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Train/valid functions","metadata":{"execution":{"iopub.status.busy":"2021-11-21T13:33:36.596973Z","iopub.execute_input":"2021-11-21T13:33:36.598099Z","iopub.status.idle":"2021-11-21T13:33:36.625852Z","shell.execute_reply.started":"2021-11-21T13:33:36.597927Z","shell.execute_reply":"2021-11-21T13:33:36.624662Z"}}},{"cell_type":"code","source":"def score_model(model, metric, data, threshold=0):\n    model.to(device).eval() # testing mode\n    scores = 0\n    threshold = torch.tensor(threshold).to(device)\n    for X_batch, Y_label in data:\n        X_batch = X_batch.to(device)\n        with torch.no_grad():\n            Y_pred = model(X_batch)\n        scores += metric((Y_pred > threshold), Y_label.to(device)).mean().item()\n    return scores/len(data)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:09:25.252746Z","iopub.execute_input":"2022-01-27T11:09:25.253574Z","iopub.status.idle":"2022-01-27T11:09:25.260817Z","shell.execute_reply.started":"2022-01-27T11:09:25.253536Z","shell.execute_reply":"2022-01-27T11:09:25.258540Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def train_model(\n    model: torch.nn.Module,\n    criterion: torch.nn.Module,\n    optimizer: torch.nn.Module,\n    dataloader_train: torch.utils.data.DataLoader,\n    dataloader_valid: torch.utils.data.DataLoader,\n    epochs: int = 100\n) -> (torch.nn.Module, dict):\n    r\"\"\"Training the model. Returns list of train losses.\n    Args:\n        model (torch.nn.Module): Neural network\n        criterion (torch.nn.Module): Cost function\n        optimizer (torch.nn.Module): Optimization algorithm\n        dataloader_train: (torch.utils.data.DataLoader): Train data\n        dataloader_valid: (torch.utils.data.DataLoader): Valid data\n        epochs (int): Number of training iterations. Default: 100\n    \"\"\"\n#def train(model, optimizer, loss_fn, epochs, data_tr, data_val):\n    X_val, Y_val = next(iter(dataloader_valid))\n    losses = []\n    metric = []\n  \n    for epoch in range(epochs):\n        avg_loss = 0\n        model.train()  # train mode\n        for X_batch, Y_batch in tqdm(dataloader_train, desc='Progress'):\n            # data to device\n            X_batch = X_batch.to(device)\n            Y_batch = Y_batch.to(device)\n            # set parameter gradients to zero\n            optimizer.zero_grad()\n            # forward\n            # print(Y_batch.shape)\n            Y_pred = model(X_batch)\n            loss = criterion(Y_pred, Y_batch)\n            print(loss)\n            loss.backward() # backward-pass\n            optimizer.step()  # update weights\n            # calculate loss to show the user\n            avg_loss += loss / len(dataloader_train)\n\n        losses.append(avg_loss.item())\n        metric.append(score_model(model, iou_pytorch, dataloader_valid))\n        \n        # show intermediate results\n        model.eval()  # testing mode\n        # detach and put into cpu\n        Y_hat = model(X_val.to(device)).detach().cpu()\n        # Visualize tools\n        clear_output(wait=True)\n        show_dermoscopic_imgs(X_val, Y_hat, threshold=0.1)\n        plt.title('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n        plt.show()\n    return losses, metric","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:20:57.891679Z","iopub.execute_input":"2022-01-27T11:20:57.892132Z","iopub.status.idle":"2022-01-27T11:20:57.903617Z","shell.execute_reply.started":"2022-01-27T11:20:57.892090Z","shell.execute_reply":"2022-01-27T11:20:57.902785Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def predict(model, data):\n    model.to(device).eval()  # testing mode\n    with torch.no_grad():\n        Y_pred = [model(X_batch.to(device)) for X_batch, _ in data]\n    return Y_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:21:17.703547Z","iopub.execute_input":"2022-01-27T11:21:17.704284Z","iopub.status.idle":"2022-01-27T11:21:17.709714Z","shell.execute_reply.started":"2022-01-27T11:21:17.704240Z","shell.execute_reply":"2022-01-27T11:21:17.708586Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# SegNet","metadata":{}},{"cell_type":"code","source":"vgg16 = torchvision.models.vgg16_bn()\nvgg16.features","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:22:01.511618Z","iopub.execute_input":"2022-01-27T11:22:01.512306Z","iopub.status.idle":"2022-01-27T11:22:03.446329Z","shell.execute_reply.started":"2022-01-27T11:22:01.512269Z","shell.execute_reply":"2022-01-27T11:22:03.445632Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class SegNet(nn.Module):\n    def _enc_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n    \n    def _dec_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n  \n    def __init__(self):\n        super().__init__()\n\n        # encoder (downsampling)\n        # Each enc_conv/dec_conv block should look like this:\n        # nn.Sequential(\n        #     nn.Conv2d(...),\n        #     ... (2 or 3 conv layers with relu and batchnorm),\n        # )\n\n        self.enc_conv0 = nn.Sequential(self._enc_layer(3, 64), self._enc_layer(64, 64))\n        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 256 -> 128\n        self.enc_conv1 = nn.Sequential(self._enc_layer(64, 128), self._enc_layer(128, 128))\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 128 -> 64\n        self.enc_conv2 = nn.Sequential(self._enc_layer(128, 256), self._enc_layer(256, 256), self._enc_layer(256, 256))\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 64 -> 32\n        self.enc_conv3 = nn.Sequential(self._enc_layer(256, 512), self._enc_layer(512, 512), self._enc_layer(512, 512))\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 32 -> 16\n        # bottleneck?\n        # self.bottleneck_conv = \n        # https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html        \n        self.enc_conv_bn = nn.Sequential(self._enc_layer(512, 512), self._enc_layer(512, 512), self._enc_layer(512, 512))\n        self.pool_bn = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, return_indices=True)\n        self.upsample_bn = nn.MaxUnpool2d(kernel_size=2, stride=2, padding=0)\n        self.dec_conv_bn = nn.Sequential(self._dec_layer(512, 512), self._dec_layer(512, 512), self._dec_layer(512, 512))\n        # decoder (upsampling)\n        self.upsample0 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 16 -> 32\n        self.dec_conv0 = nn.Sequential(self._dec_layer(512, 512), self._dec_layer(512, 512), self._dec_layer(512, 256))\n        self.upsample1 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 32 -> 64\n        self.dec_conv1 = nn.Sequential(self._dec_layer(256, 256), self._dec_layer(256, 256), self._dec_layer(256, 128))\n        self.upsample2 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 64 -> 128\n        self.dec_conv2 = nn.Sequential(self._dec_layer(128, 128), self._dec_layer(128, 64))\n        self.upsample3 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 128 -> 256\n        self.dec_conv3 = nn.Sequential(\n            self._dec_layer(64, 64),\n            nn.ConvTranspose2d(64, 1, kernel_size=(3, 3), padding=(1, 1)),\n            # nn.BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n            # nn.ReLU(inplace=True)\n       )\n\n    def forward(self, x):\n        # encoder\n        e0, idx0 = self.pool0(self.enc_conv0(x))\n        e1, idx1 = self.pool1(self.enc_conv1(e0))\n        e2, idx2 = self.pool2(self.enc_conv2(e1))\n        e3, idx3 = self.pool3(self.enc_conv3(e2))\n\n        # bottleneck\n        # b = self.bottleneck_conv(e3)\n        p, idx_bn = self.pool_bn(self.enc_conv_bn(e3))\n        b = self.dec_conv_bn(self.upsample_bn(p, idx_bn))\n        \n        # decoder\n        d0 = self.dec_conv0(self.upsample0(b, idx3))\n        d1 = self.dec_conv1(self.upsample1(d0, idx2))\n        d2 = self.dec_conv2(self.upsample2(d1, idx1))\n        d3 = self.dec_conv3(self.upsample3(d2, idx0)) # no activation\n        return d3","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:22:42.783912Z","iopub.execute_input":"2022-01-27T11:22:42.784260Z","iopub.status.idle":"2022-01-27T11:22:42.809783Z","shell.execute_reply.started":"2022-01-27T11:22:42.784221Z","shell.execute_reply":"2022-01-27T11:22:42.809097Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"segnet = SegNet().to(device)\n# segnet\nsummary(segnet, input_size=(3, 256, 256), batch_size=batch_size)\ndel segnet","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:23:24.875769Z","iopub.execute_input":"2022-01-27T11:23:24.876139Z","iopub.status.idle":"2022-01-27T11:23:32.932973Z","shell.execute_reply.started":"2022-01-27T11:23:24.876098Z","shell.execute_reply":"2022-01-27T11:23:32.932247Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"segnet = SegNet().to(device)\noptim = torch.optim.Adam(segnet.parameters(), lr=1e-4)\n#loss_func = BCELoss_with_logits()\nloss_func = FocalTverskyLoss(0.6, 0.4, 2)\nlosses, metric = train_model(segnet, loss_func, optim, dataloader_train, dataloader_valid, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:25:23.333063Z","iopub.execute_input":"2022-01-27T11:25:23.333515Z","iopub.status.idle":"2022-01-27T11:31:20.724431Z","shell.execute_reply.started":"2022-01-27T11:25:23.333479Z","shell.execute_reply":"2022-01-27T11:31:20.723742Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"score_model(segnet, iou_pytorch, dataloader_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:47:09.550426Z","iopub.execute_input":"2022-01-27T11:47:09.550683Z","iopub.status.idle":"2022-01-27T11:47:09.770594Z","shell.execute_reply.started":"2022-01-27T11:47:09.550654Z","shell.execute_reply":"2022-01-27T11:47:09.769766Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"# UNet","metadata":{}},{"cell_type":"code","source":"class UNet(nn.Module):\n    \n    def _conv_conv(self,in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n    \n    def _enc_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            self._conv_conv(in_channels, out_channels)\n        )\n    \n    def __init__(self):\n        super().__init__()\n        \n        # encoder (downsampling)\n        # Each enc_conv/dec_conv block should look like this:\n        # nn.Sequential(\n        #     nn.Conv2d(...),\n        #     ... (2 or 3 conv layers with relu and batchnorm),\n        # )\n        \n        self.enc_conv0 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n        self.enc_lr0 = self._enc_layer(64, 128)\n        self.enc_lr1 = self._enc_layer(128, 256)\n        self.enc_lr2 = self._enc_layer(256, 512)\n        self.enc_lr3 = self._enc_layer(512, 512)\n        # decoder (upsampling)\n        self.upsample0 = nn.Upsample(scale_factor=2)#ConvTranspose2d(1024, 512, kernel_size=2, stride=2) # 16 -> 32\n        self.dec_conv0 = self._conv_conv(2 * 512, 256)\n        self.upsample1 = nn.Upsample(scale_factor=2)#nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) # 32 -> 64\n        self.dec_conv1 = self._conv_conv(2 * 256, 128)\n        self.upsample2 = nn.Upsample(scale_factor=2)#nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) # 64 -> 128\n        self.dec_conv2 = self._conv_conv(2 * 128, 64)\n        self.upsample3 = nn.Upsample(scale_factor=2)#nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)  # 128 -> 256\n        self.dec_conv3 = nn.Sequential(\n            self._conv_conv(2 * 64, 64),\n            nn.Conv2d(64, 1, kernel_size=1),\n        )\n\n    def forward(self, x):\n        # encoder\n        e0 = self.enc_conv0(x)\n        e1 = self.enc_lr0(e0)\n        e2 = self.enc_lr1(e1)\n        e3 = self.enc_lr2(e2)\n        # bottleneck\n        b = self.upsample0(self.enc_lr3(e3))\n\n        # decoder\n        d0 = self.upsample1(self.dec_conv0(torch.cat((b, e3), dim=1)))\n        d1 = self.upsample2(self.dec_conv1(torch.cat((d0, e2), dim=1)))\n        d2 = self.upsample3(self.dec_conv2(torch.cat((d1, e1), dim=1)))\n        d3 = self.dec_conv3(torch.cat((d2, e0), dim=1))  # no activation\n        return d3","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:33:23.544035Z","iopub.execute_input":"2022-01-27T11:33:23.544464Z","iopub.status.idle":"2022-01-27T11:33:23.561512Z","shell.execute_reply.started":"2022-01-27T11:33:23.544427Z","shell.execute_reply":"2022-01-27T11:33:23.560814Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"unet = UNet().to(device)\n# unet\nsummary(unet, input_size=(3, 256, 256), batch_size=batch_size)\ndel unet","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:33:33.945196Z","iopub.execute_input":"2022-01-27T11:33:33.945466Z","iopub.status.idle":"2022-01-27T11:33:34.104920Z","shell.execute_reply.started":"2022-01-27T11:33:33.945437Z","shell.execute_reply":"2022-01-27T11:33:34.104143Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"unet = UNet().to(device)\noptim = torch.optim.Adam(unet.parameters(), lr=1e-4)\nloss_func = LovaszLoss()\nlosses, metric = train_model(unet, loss_func, optim, dataloader_train, dataloader_valid, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:34:41.208617Z","iopub.execute_input":"2022-01-27T11:34:41.208997Z","iopub.status.idle":"2022-01-27T11:39:46.491520Z","shell.execute_reply.started":"2022-01-27T11:34:41.208959Z","shell.execute_reply":"2022-01-27T11:39:46.490906Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"score_model(unet, iou_pytorch, dataloader_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:46:55.748039Z","iopub.execute_input":"2022-01-27T11:46:55.748620Z","iopub.status.idle":"2022-01-27T11:46:55.956988Z","shell.execute_reply.started":"2022-01-27T11:46:55.748577Z","shell.execute_reply":"2022-01-27T11:46:55.956242Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"class UNet2(nn.Module):\n    \n    def _conv_conv(self,in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n    \n    def _enc_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1),\n            self._conv_conv(in_channels, out_channels)\n        )\n    \n    def __init__(self):\n        super().__init__()\n        \n        # encoder (downsampling)\n        # Each enc_conv/dec_conv block should look like this:\n        # nn.Sequential(\n        #     nn.Conv2d(...),\n        #     ... (2 or 3 conv layers with relu and batchnorm),\n        # )\n        \n        self.enc_conv0 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n        self.enc_lr0 = self._enc_layer(64, 128)\n        self.enc_lr1 = self._enc_layer(128, 256)\n        self.enc_lr2 = self._enc_layer(256, 512)\n        self.enc_lr3 = self._enc_layer(512, 1024)\n        # decoder (upsampling)\n        self.upsample0 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2) # 16 -> 32\n        self.dec_conv0 = self._conv_conv(2 * 512, 512)\n        self.upsample1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) # 32 -> 64\n        self.dec_conv1 = self._conv_conv(2 * 256, 256)\n        self.upsample2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) # 64 -> 128\n        self.dec_conv2 = self._conv_conv(2 * 128, 128)\n        self.upsample3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)  # 128 -> 256\n        self.dec_conv3 = nn.Sequential(\n            self._conv_conv(2 * 64, 64),\n            nn.Conv2d(64, 1, kernel_size=1),\n        )\n\n    def forward(self, x):\n        # encoder\n        e0 = self.enc_conv0(x)\n        e1 = self.enc_lr0(e0)\n        e2 = self.enc_lr1(e1)\n        e3 = self.enc_lr2(e2)\n        # bottleneck\n        b = self.upsample0(self.enc_lr3(e3))\n\n        # decoder\n        d0 = self.upsample1(self.dec_conv0(torch.cat((b, e3), dim=1)))\n        d1 = self.upsample2(self.dec_conv1(torch.cat((d0, e2), dim=1)))\n        d2 = self.upsample3(self.dec_conv2(torch.cat((d1, e1), dim=1)))\n        d3 = self.dec_conv3(torch.cat((d2, e0), dim=1))  # no activation\n        return d3","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-27T11:40:18.827546Z","iopub.execute_input":"2022-01-27T11:40:18.827804Z","iopub.status.idle":"2022-01-27T11:40:18.844414Z","shell.execute_reply.started":"2022-01-27T11:40:18.827772Z","shell.execute_reply":"2022-01-27T11:40:18.843725Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"unet2 = UNet2().to(device)\n# unet2\nsummary(unet2, input_size=(3, 256, 256), batch_size=batch_size)\ndel unet2","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:40:27.764552Z","iopub.execute_input":"2022-01-27T11:40:27.764997Z","iopub.status.idle":"2022-01-27T11:40:28.337504Z","shell.execute_reply.started":"2022-01-27T11:40:27.764958Z","shell.execute_reply":"2022-01-27T11:40:28.336751Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"unet2 = UNet2().to(device)\noptim = torch.optim.Adam(unet.parameters(), lr=1e-4)\nloss_func = LovaszLoss()\nlosses, metric = train_model(unet, loss_func, optim, dataloader_train, dataloader_valid, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:40:42.418123Z","iopub.execute_input":"2022-01-27T11:40:42.418665Z","iopub.status.idle":"2022-01-27T11:45:48.635270Z","shell.execute_reply.started":"2022-01-27T11:40:42.418625Z","shell.execute_reply":"2022-01-27T11:45:48.633557Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"score_model(unet2, iou_pytorch, dataloader_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:48:06.718981Z","iopub.execute_input":"2022-01-27T11:48:06.719236Z","iopub.status.idle":"2022-01-27T11:48:06.996545Z","shell.execute_reply.started":"2022-01-27T11:48:06.719209Z","shell.execute_reply":"2022-01-27T11:48:06.995855Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Model validation","metadata":{}},{"cell_type":"code","source":"def validate_model(model_class, model_file, pickle_file, max_epochs=100):\n    loss = {\n        #'bce': BCELoss_with_logits(reduction='mean', truncate=True),\n        'bce': BCELoss_classic(reduction='mean'),\n        #'bce': nn.BCEWithLogitsLoss(reduction='mean'),\n        'dice': DiceLoss(),\n        'focal': FocalLoss(),\n        'tversky': TverskyLoss(alpha=0.7, beta = 0.3),\n        'focal_tversky': FocalTverskyLoss(alpha=0.6, beta = 0.4, gamma=2),\n        'lovasz': LovaszLoss(),\n    }\n    model_history = {}\n    for loss_name, loss_func in loss.items():\n        model_history[loss_name] = {}\n        model = model_class().to(device)\n        optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n        losses, metric = train_model(model, loss_func, optim, dataloader_train, dataloader_valid, max_epochs)\n        model_history[loss_name]['losses'] = losses\n        model_history[loss_name]['metric'] = metric\n        torch.save(model, '{}_{}_{}epoch.model'.format(model_file, loss_name, max_epochs))\n    with open(pickle_file, 'wb') as handle:\n        pickle.dump(model_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    return model_history","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:49:48.645869Z","iopub.execute_input":"2022-01-27T11:49:48.646485Z","iopub.status.idle":"2022-01-27T11:49:48.655500Z","shell.execute_reply.started":"2022-01-27T11:49:48.646446Z","shell.execute_reply":"2022-01-27T11:49:48.654808Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"max_epochs = 100\nsegnet_history = validate_model(SegNet, 'segnet', 'segnet.pickle', max_epochs=max_epochs)\nunet_history = validate_model(UNet, 'unet', 'unet.pickle', max_epochs=max_epochs)\nunet2_history = validate_model(UNet2, 'unet2', 'unet2.pickle', max_epochs=max_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T11:49:58.518681Z","iopub.execute_input":"2022-01-27T11:49:58.518975Z","iopub.status.idle":"2022-01-27T13:39:50.321978Z","shell.execute_reply.started":"2022-01-27T11:49:58.518944Z","shell.execute_reply":"2022-01-27T13:39:50.321125Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# with open('../input/temporary/segnet.pickle', 'rb') as handle:\n#     segnet_history = pickle.load(handle)\n# with open('../input/temporary/unet.pickle', 'rb') as handle:\n#     unet_history = pickle.load(handle)\n# with open('../input/temporary/unet2.pickle', 'rb') as handle:\n#     unet2_history = pickle.load(handle)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set(context='paper')\n\nfor history in [segnet_history, unet_history, unet2_history]:\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    x = list(range(max_epochs))\n    for key, value in history.items():\n        sns.lineplot(x=x, y=value['losses'], ax=ax[0], label=key)\n        sns.lineplot(x=x, y=value['metric'], ax=ax[1], label=key)\n    ax[0].set_title('loss')\n    ax[1].set_title('IoU')\n    ax[0].legend()\n    ax[1].legend()\n    fig.show()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-27T13:42:23.826038Z","iopub.execute_input":"2022-01-27T13:42:23.826343Z","iopub.status.idle":"2022-01-27T13:42:26.168671Z","shell.execute_reply.started":"2022-01-27T13:42:23.826309Z","shell.execute_reply":"2022-01-27T13:42:26.168023Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"for history in [segnet_history, unet_history, unet2_history]:\n    ax = sns.barplot(x=list(history.keys()), y=[max(m['metric']) for m in history.values()])\n    ax.bar_label(ax.containers[0])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T13:40:54.833632Z","iopub.execute_input":"2022-01-27T13:40:54.834069Z","iopub.status.idle":"2022-01-27T13:40:56.216400Z","shell.execute_reply.started":"2022-01-27T13:40:54.834025Z","shell.execute_reply":"2022-01-27T13:40:56.215725Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Resume","metadata":{}},{"cell_type":"markdown","source":"**SegNet**\n\n* Total params: 29,443,585\n* Params size (MB): 112.32\n   \n**Unet (MaxPool2d/Upsample)**\n\n* Total params: 13,387,393\n* Params size (MB): 51.07\n\n**UNet (Conv2d/ConvTranspose2d)**\n\n* Total params: 34,166,145\n* Params size (MB): 130.33","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}